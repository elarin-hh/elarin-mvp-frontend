# Elarin MVP - AI-Powered Personal Training Platform

> Plataforma de treino pessoal com intelig√™ncia artificial para an√°lise de movimento em tempo real

## üéØ Sobre o Projeto

Elarin √© uma plataforma MVP que utiliza Computer Vision e Machine Learning para analisar exerc√≠cios f√≠sicos em tempo real, fornecendo feedback instant√¢neo sobre a execu√ß√£o correta dos movimentos.

### Caracter√≠sticas Principais

- ‚úÖ An√°lise h√≠brida (ML + Heur√≠sticas biomec√¢nicas)
- ‚úÖ Feedback visual em tempo real
- ‚úÖ Detec√ß√£o de 33 pontos do corpo (MediaPipe Pose)
- ‚úÖ Processamento 100% no navegador (privacidade)
- ‚úÖ PWA instal√°vel (funciona offline)
- ‚úÖ Multiplataforma (desktop + mobile)
- ‚úÖ **100% TypeScript** (sistema de vis√£o completo)

## üèóÔ∏è Estrutura do Projeto

```
elarin-mvp-frontend/
‚îú‚îÄ‚îÄ src/                      # C√≥digo-fonte TypeScript
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/       # Componentes Svelte reutiliz√°veis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stores/           # State management (Svelte Stores)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vision/           # ‚ú® Computer Vision System (TypeScript)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types/        # Type definitions
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ constants/    # MediaPipe landmarks
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/        # Fun√ß√µes utilit√°rias (√¢ngulos, dist√¢ncias)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validators/   # Validadores heur√≠sticos (Squat, Lunge)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/         # FeedbackSystem, ExerciseAnalyzer
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml/           # GenericClassifier (ONNX)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/       # Carregador de configura√ß√µes
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts      # Export principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/              # Clientes REST
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/            # Types globais
‚îÇ   ‚îî‚îÄ‚îÄ routes/               # SvelteKit routes (file-based)
‚îÇ       ‚îú‚îÄ‚îÄ (auth)/           # P√°ginas autenticadas
‚îÇ       ‚îú‚îÄ‚îÄ login/            # Login
‚îÇ       ‚îú‚îÄ‚îÄ register/         # Registro
‚îÇ       ‚îú‚îÄ‚îÄ exercises/        # Lista de exerc√≠cios
‚îÇ       ‚îú‚îÄ‚îÄ train/            # Treino com pose detection
‚îÇ       ‚îî‚îÄ‚îÄ framer/           # An√°lise de v√≠deo frame-by-frame
‚îú‚îÄ‚îÄ static/                   # Assets est√°ticos
‚îÇ   ‚îú‚îÄ‚îÄ assets/               # Imagens, CSS
‚îÇ   ‚îú‚îÄ‚îÄ icons/                # √çcones e favicons
‚îÇ   ‚îú‚îÄ‚îÄ models/               # Modelos ML (ONNX)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ squat/            # Modelo squat + metadata
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lunge/            # Modelo lunge + metadata
‚îÇ   ‚îî‚îÄ‚îÄ exercises.json        # Cat√°logo de exerc√≠cios
‚îú‚îÄ‚îÄ .husky/                   # Git hooks (pre-commit)
‚îú‚îÄ‚îÄ package.json              # Depend√™ncias e scripts
‚îú‚îÄ‚îÄ vite.config.ts            # Configura√ß√£o Vite
‚îú‚îÄ‚îÄ svelte.config.js          # Configura√ß√£o SvelteKit
‚îú‚îÄ‚îÄ tsconfig.json             # Configura√ß√£o TypeScript
‚îú‚îÄ‚îÄ tailwind.config.cjs       # Configura√ß√£o Tailwind CSS
‚îî‚îÄ‚îÄ README.md                 # Este arquivo
```

## üöÄ Quick Start

### Pr√©-requisitos

- **Node.js** >= 20
- **pnpm** >= 9

### Instala√ß√£o

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/your-org/elarin-mvp-frontend.git
cd elarin-mvp-frontend

# 2. Instale as depend√™ncias
pnpm install

# 3. Configure vari√°veis de ambiente (opcional)
# Crie .env com:
# PUBLIC_SUPABASE_URL=...
# PUBLIC_SUPABASE_ANON_KEY=...

# 4. Inicie o servidor de desenvolvimento
pnpm dev

# 5. Abra no navegador
# http://localhost:5173
```

## üì¶ Scripts Dispon√≠veis

```bash
pnpm dev          # Inicia servidor de desenvolvimento (http://localhost:5173)
pnpm build        # Build de produ√ß√£o (output em build/)
pnpm preview      # Preview do build de produ√ß√£o
pnpm lint         # Roda ESLint
pnpm format       # Formata c√≥digo com Prettier
pnpm typecheck    # Verifica tipos TypeScript
pnpm test         # Roda testes com Vitest
pnpm clean        # Limpa node_modules e build artifacts
```

## üé® Stack Tecnol√≥gica

### Frontend
- **Framework**: SvelteKit 2.8 + Svelte 5
- **Language**: TypeScript 5.6 (strict mode)
- **Styling**: Tailwind CSS 3.4
- **Build**: Vite 6.3
- **State**: Svelte Stores
- **i18n**: svelte-i18n

### Computer Vision & ML
- **Pose Detection**: MediaPipe Pose (33 landmarks)
- **ML Runtime**: ONNX Runtime Web 1.23
- **Model**: Autoencoder (One-Class Learning)
- **Processing**: 100% client-side (privacidade garantida)
- **Validators**: Heur√≠sticas biomec√¢nicas customizadas

### Backend & Infra
- **BaaS**: Supabase (PostgreSQL + Auth + Storage)
- **Hosting**: Static build (Vercel/Netlify/Cloudflare Pages)
- **PWA**: Vite PWA Plugin

### Quality & Testing
- **Linter**: ESLint 8 + TypeScript ESLint
- **Formatter**: Prettier 3
- **Unit Tests**: Vitest 2.1
- **E2E Tests**: Playwright 1.48
- **Type Safety**: TypeScript strict mode
- **Git Hooks**: Husky + lint-staged

## üíª Sistema de Vis√£o Computacional

### Arquitetura

O sistema de vis√£o √© **100% TypeScript** com arquitetura modular:

```typescript
import {
  ExerciseAnalyzer,
  FeedbackSystem,
  SquatValidator,
  LungeValidator,
  GenericExerciseClassifier,
  loadExerciseConfig,
  MEDIAPIPE_LANDMARKS,
  calculateAngle,
  type PoseLandmarks,
  type FeedbackRecord
} from '$lib/vision';

// 1. Carregar configura√ß√£o do exerc√≠cio
const config = await loadExerciseConfig('squat');

// 2. Criar analisador
const analyzer = new ExerciseAnalyzer(config);

// 3. Inicializar (carrega modelo ONNX + validator)
await analyzer.initialize();

// 4. Configurar callbacks
analyzer.setCallbacks({
  onFeedback: (feedback: FeedbackRecord) => {
    console.log('Verdict:', feedback.combined.verdict);
    console.log('Confidence:', feedback.combined.confidence);
    console.log('Messages:', feedback.messages);
  },
  onMetricsUpdate: (metrics) => {
    console.log('Reps:', metrics.validReps);
    console.log('Accuracy:', metrics.accuracy);
  }
});

// 5. Analisar frames (chamado a cada detec√ß√£o de pose)
async function onPoseDetected(landmarks: PoseLandmarks) {
  const feedback = await analyzer.analyzeFrame(landmarks);
  // Processar feedback...
}

// 6. Configurar modo de feedback
analyzer.setFeedbackMode('hybrid'); // 'ml_only' | 'heuristic_only' | 'hybrid'
```

### Modos de Feedback

1. **Hybrid Mode** (Recomendado)
   - Combina ML (autoencoder) + Heur√≠sticas biomec√¢nicas
   - Maior acur√°cia (~95%)
   - Feedback espec√≠fico (ex: "joelho passando do p√©")

2. **ML Only**
   - Apenas detec√ß√£o de anomalias com autoencoder
   - Feedback gen√©rico
   - √ötil para movimentos novos

3. **Heuristic Only**
   - Apenas regras biomec√¢nicas
   - Feedback muito espec√≠fico
   - N√£o requer modelo treinado

### Validators Dispon√≠veis

- **SquatValidator**: Valida agachamento (profundidade, simetria, postura)
- **LungeValidator**: Valida afundo (joelho, tronco, estabilidade)
- **BaseValidator**: Classe base para criar novos validators

## üéØ Funcionalidades

### ‚úÖ Implementadas

- [x] Autentica√ß√£o (Supabase Auth)
- [x] Detec√ß√£o de pose em tempo real (MediaPipe)
- [x] An√°lise h√≠brida ML + Heur√≠sticas
- [x] Exerc√≠cios: Squat, Lunge
- [x] Feedback visual (esqueleto colorido)
- [x] Contador de repeti√ß√µes autom√°tico
- [x] Modo h√≠brido/ML/Heur√≠stico selecion√°vel
- [x] PWA instal√°vel
- [x] Sistema 100% TypeScript

### üöß Em Desenvolvimento

- [ ] Push-up e Plank validators
- [ ] Hist√≥rico de treinos
- [ ] Estat√≠sticas e progress√£o
- [ ] Planos de treino personalizados
- [ ] Modo multi-usu√°rio
- [ ] Export de treinos (PDF/JSON)

## üìä M√©tricas de Performance

- **FPS**: 25-30 (detec√ß√£o de pose)
- **Lat√™ncia ML**: 15-30ms (infer√™ncia ONNX)
- **Lat√™ncia Heur√≠stica**: <5ms
- **Lat√™ncia Total**: ~35ms (end-to-end)
- **Acur√°cia**: ~95% (modo h√≠brido)
- **Bundle Size**: ~2.5MB (gzipped: ~800KB)

## üîí Privacidade e Seguran√ßa

- ‚úÖ Processamento 100% client-side (navegador)
- ‚úÖ V√≠deo **NUNCA** enviado ao servidor
- ‚úÖ Apenas landmarks (coordenadas x,y,z) processados
- ‚úÖ Autentica√ß√£o segura (Supabase)
- ‚úÖ HTTPS obrigat√≥rio em produ√ß√£o
- ‚úÖ Dados pessoais criptografados

## üì± Compatibilidade

### Navegadores Suportados

- ‚úÖ Chrome/Edge 90+
- ‚úÖ Firefox 88+
- ‚úÖ Safari 14+
- ‚úÖ Mobile (Chrome/Safari iOS 14+)

### Requisitos M√≠nimos

- Webcam/c√¢mera frontal
- Conex√£o de internet (para carregar modelos ONNX)
- 4GB RAM
- Processador dual-core
- Resolu√ß√£o m√≠nima: 720p

## ü§ù Contribuindo

### Workflow de Desenvolvimento

1. Crie uma branch a partir de `main`
2. Fa√ßa suas altera√ß√µes seguindo as conven√ß√µes
3. Rode `pnpm lint` e `pnpm typecheck`
4. Escreva/atualize testes
5. Commit com mensagens sem√¢nticas
6. Abra um Pull Request

### Conven√ß√µes

- **Commits**: Conventional Commits (`feat:`, `fix:`, `docs:`, etc)
- **Code Style**: Prettier + ESLint (auto-formata√ß√£o no save)
- **Branches**: `feature/nome`, `fix/nome`, `refactor/nome`
- **TypeScript**: Strict mode habilitado (sem `any`)
- **Components**: PascalCase para arquivos `.svelte`
- **Utilities**: camelCase para `.ts`

### Criar Novo Validator

```typescript
import { BaseValidator } from '$lib/vision/validators/BaseValidator';
import type { PoseLandmarks, ValidationResult } from '$lib/vision/types';
import { MEDIAPIPE_LANDMARKS } from '$lib/vision/constants/mediapipe.constants';
import { calculateAngle } from '$lib/vision/utils/angles.utils';

export class PushupValidator extends BaseValidator {
  validate(landmarks: PoseLandmarks, frameCount: number): ValidationResult {
    this.currentIssues = [];

    // Sua l√≥gica aqui
    const leftElbow = landmarks[MEDIAPIPE_LANDMARKS.LEFT_ELBOW];
    const leftShoulder = landmarks[MEDIAPIPE_LANDMARKS.LEFT_SHOULDER];
    const leftWrist = landmarks[MEDIAPIPE_LANDMARKS.LEFT_WRIST];

    if (this.isVisible(leftElbow) && this.isVisible(leftShoulder) && this.isVisible(leftWrist)) {
      const elbowAngle = calculateAngle(leftShoulder, leftElbow, leftWrist);

      if (elbowAngle < 90) {
        this.currentIssues.push({
          message: 'Cotovelo muito flexionado',
          severity: 'high'
        });
      }
    }

    return {
      isValid: this.currentIssues.length === 0,
      issues: this.currentIssues
    };
  }
}
```

## üêõ Troubleshooting

### Erro: "Model not found"
- Verifique se os arquivos `.onnx` est√£o em `static/models/`
- Rode `pnpm build` para copiar assets

### Erro: "Camera permission denied"
- Habilite permiss√£o de c√¢mera nas configura√ß√µes do navegador
- Use HTTPS (http://localhost √© permitido)

### Pose n√£o detectada
- Garanta boa ilumina√ß√£o
- Fique de corpo inteiro na c√¢mera
- Fundo limpo ajuda na detec√ß√£o

### Build falhou
- Limpe cache: `pnpm clean && pnpm install`
- Verifique tipos: `pnpm typecheck`
- Verifique Node.js vers√£o >= 20

## üìÑ Licen√ßa

MIT License - veja [LICENSE](./LICENSE) para detalhes.

## üë• Equipe

- **Eduardo** - Lead Developer & Computer Vision Engineer

## üîó Links √öteis

- [MediaPipe Pose](https://google.github.io/mediapipe/solutions/pose)
- [ONNX Runtime](https://onnxruntime.ai/)
- [SvelteKit Docs](https://kit.svelte.dev/)
- [Tailwind CSS](https://tailwindcss.com/)

---

**Vers√£o**: 0.1.0
**Status**: MVP em produ√ß√£o
**√öltima Atualiza√ß√£o**: 19/10/2025

---

<div align="center">
  Feito com ‚ù§Ô∏è para melhorar a sa√∫de e bem-estar atrav√©s da tecnologia
</div>
